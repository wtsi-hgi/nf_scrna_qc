// General resource configuration applicable to all profiles
workDir =    "${launchDir}/work"
tmpDir =     "${launchDir}/tmp"
reportdir =  "${launchDir}/reports"
output_dir = "${launchDir}/results"
timeline {
  enabled = true
  file = "${params.reportdir}/timeline.html"
}

trace {
  enabled = true
  file = "${params.reportdir}/trace.txt"
}

process {
    // make sure that the container imate is available to mercury in cacheDir
    container =	'nf_qc_cluster_2.4'
    // container =	'sc_qc_cluster_latest'

    // error strategy
    errorStrategy = 'retry'
    //errorStrategy = 'terminate'
    maxRetries = 2

    // basic resources
    cpus = 1
    memory = 15.GB
    //time = { 20.m * task.attempt }

    // basic output settings
    publish_mode = "rellink" // symlink or copy

    withName: sccaf_assess_clustering {
        memory = { 25.GB * task.attempt }
    	container =	'nf_qc_cluster_sccaf_1.5'
    }
    withName: sccaf_optimize_clustering {
        memory = { 25.GB * task.attempt }
    	container =	'nf_qc_cluster_sccaf_1.5'
    }

    // process-specific resources
    withName: run_scrublet {
        memory = { 25.GB * task.attempt }
    }
    withName: make_cellmetadata_pipeline_input {
        memory = { 5.GB * task.attempt }
    }
    withName: merge_samples {
        memory = { 20.GB * task.attempt }
    }
    withName: normalize_and_pca {
        memory = { 50.GB * task.attempt }
        cpus = 8
    }
    withName: subset_pcs {
        memory = { 5.GB * task.attempt }
    }
    withName: harmony {
        memory = { 20.GB * task.attempt }
    }
    withName: bbknn {
        memory = { 20.GB * task.attempt }
        cpus = 4
    }
    withName: cluster {
        memory = { 20.GB * task.attempt }
        cpus = 4
    }
    withName: cluster_validate_resolution_sklearn {
        memory = { 40.GB * task.attempt }
        cpus = { 8 * task.attempt }
    }
    // Tensorflow wants to use all available memory on a GPU, so make sure we
    // request lots of memory. Most nodes have 754.5G on Sanger farm, so
    // request ~1/2.
    withName: cluster_validate_resolution_keras {
        memory = 370.GB
        //memory = 150.GB
        cpus = 1
    }
    withName: sccaf_assess_clustering {
        memory = { 16.GB * task.attempt }
        cpus = 1 //{ 4 * task.attempt }
    }
    withName: plot_resolution_validate {
        memory = { 20.GB * task.attempt }
        cpus = 1
    }
    withName: cluster_markers {
        memory = { 15.GB * task.attempt }
        cpus = 4
    }
    withName: merge_clusters {
        memory = { 30.GB * task.attempt }
        cpus = 8
    }
    withName: convert_seurat {
        memory = { 60.GB * task.attempt }
    }
    withName: umap_calculate {
        memory = { 50.GB * task.attempt }
        cpus = 8
    }
    withName: umap_gather {
        memory = { 70.GB + 30.GB * task.attempt }
    }
    withName: umap_calculate_and_plot {
        memory = { 50.GB * task.attempt }
        cpus = 8
    }
    withName: split_h5ad_by_batch {
      memory = { 8.GB * task.attempt }
      cpus = 1
    }
    withName: assign_cell_types_azimuth {
      memory = { 6.GB * task.attempt }
      cpus = 1
      stageInMode = 'copy'
      container = 'seurat_azimuth_pbmc_1.0'
      // singularity pull seurat_azimuth_pbmc_1.0.img docker://wtsihgi/seurat_azimuth_pbmc:1.2
    }
    withName: gather_minimal_dataset {
      memory = { 2.GB * task.attempt }
      cpus = 1
    }
} // end process
